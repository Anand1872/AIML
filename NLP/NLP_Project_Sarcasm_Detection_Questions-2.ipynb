{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pp68FAQf9aMN"
   },
   "source": [
    "# Sarcasm Detection\n",
    " **Acknowledgement**\n",
    "\n",
    "Misra, Rishabh, and Prahal Arora. \"Sarcasm Detection using Hybrid Neural Network.\" arXiv preprint arXiv:1908.07414 (2019).\n",
    "\n",
    "**Required Files given in below link.**\n",
    "\n",
    "https://drive.google.com/drive/folders/1xUnF35naPGU63xwRDVGc-DkZ3M8V5mMk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S3Wj_mIZ8S3K"
   },
   "source": [
    "## Install `Tensorflow2.0` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jW2Uk8otQvi8",
    "outputId": "2c601f49-8615-463b-af04-48be64ea74ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.0.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2a/5c/f1d66de5dde6f3ff528f6ea1fd0757a0e594d17debb3ec7f82daa967ea9a/tensorflow-2.0.0-cp37-cp37m-manylinux2010_x86_64.whl (86.3MB)\n",
      "\u001b[K     |████████████████████████████████| 86.3MB 94kB/s \n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0) (3.12.4)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0) (1.12.1)\n",
      "Collecting tensorflow-estimator<2.1.0,>=2.0.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/08/8b927337b7019c374719145d1dceba21a8bb909b93b1ad6f8fb7d22c1ca1/tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449kB)\n",
      "\u001b[K     |████████████████████████████████| 450kB 32.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0) (0.2.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0) (0.10.0)\n",
      "Collecting keras-applications>=1.0.8\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 6.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0) (1.1.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0) (1.19.5)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0) (0.8.1)\n",
      "Collecting gast==0.2.2\n",
      "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0) (0.36.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0) (1.1.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0) (3.3.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0) (1.15.0)\n",
      "Collecting tensorboard<2.1.0,>=2.0.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/54/99b9d5d52d5cb732f099baaaf7740403e83fe6b0cedde940fabd2b13d75a/tensorboard-2.0.2-py3-none-any.whl (3.8MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8MB 23.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0) (1.32.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow==2.0.0) (53.0.0)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==2.0.0) (2.10.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.27.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.4.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2.23.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.3.4)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.0.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (4.2.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.3.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2020.12.5)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.7.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.4.0)\n",
      "Building wheels for collected packages: gast\n",
      "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for gast: filename=gast-0.2.2-cp37-none-any.whl size=7540 sha256=3c116d5d37d17963892dae7d5fc71a3fe76d5d896922b9db32f8ee9e79ae0e54\n",
      "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
      "Successfully built gast\n",
      "\u001b[31mERROR: tensorflow-probability 0.12.1 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
      "Installing collected packages: tensorflow-estimator, keras-applications, gast, tensorboard, tensorflow\n",
      "  Found existing installation: tensorflow-estimator 2.4.0\n",
      "    Uninstalling tensorflow-estimator-2.4.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
      "  Found existing installation: gast 0.3.3\n",
      "    Uninstalling gast-0.3.3:\n",
      "      Successfully uninstalled gast-0.3.3\n",
      "  Found existing installation: tensorboard 2.4.1\n",
      "    Uninstalling tensorboard-2.4.1:\n",
      "      Successfully uninstalled tensorboard-2.4.1\n",
      "  Found existing installation: tensorflow 2.4.1\n",
      "    Uninstalling tensorflow-2.4.1:\n",
      "      Successfully uninstalled tensorflow-2.4.1\n",
      "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-2.0.2 tensorflow-2.0.0 tensorflow-estimator-2.0.1\n"
     ]
    }
   ],
   "source": [
    "!!pip uninstall tensorflow\n",
    "!pip install tensorflow==2.0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v9kv9tyJ77eF"
   },
   "source": [
    "## Get Required Files from Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D0O_n6OIEVyL",
    "outputId": "a5abec4a-6aec-4906-d9fa-0b8e3605fdf8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "0mgRpOvFMjKR"
   },
   "outputs": [],
   "source": [
    "#Set your project path \n",
    "project_path =  '/content/drive/MyDrive/Sarcasm Detection/Data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ASzNV0nLybin",
    "outputId": "944f6df5-db0c-40e5-8742-ac173eb2b683"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/.shortcut-targets-by-id/1xUnF35naPGU63xwRDVGc-DkZ3M8V5mMk/Sarcasm Detection/Data\n"
     ]
    }
   ],
   "source": [
    "cd drive/MyDrive/Sarcasm Detection/Data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J0ywSB1Tygi8",
    "outputId": "425194a0-a97f-40e1-8478-7025424d9171"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glove.6B.100d.txt  glove.6B.300d.txt  glove.6B.zip\n",
      "glove.6B.200d.txt  glove.6B.50d.txt   Sarcasm_Headlines_Dataset.json\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WXYwajPeQbRq"
   },
   "source": [
    "#**## Reading and Exploring Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vAk6BRUh8CqL"
   },
   "source": [
    "## Read Data \"Sarcasm_Headlines_Dataset.json\". Explore the data and get  some insights about the data. ( 4 marks)\n",
    "Hint - As its in json format you need to use pandas.read_json function. Give paraemeter lines = True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "StSLB-T8PuGr"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "sarcasm_head = pd.read_json('Sarcasm_Headlines_Dataset.json', lines=True)\n",
    "#sarcasm_head = pd.read_json(project_path + 'Sarcasm_Headlines_Dataset.json',orient='split')\n",
    "#, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 585
    },
    "id": "RgSeh99KzSlk",
    "outputId": "70d4e226-396a-4d8e-a0c8-a923a4d77441"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_link</th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/versace-b...</td>\n",
       "      <td>former versace store clerk sues over secret 'b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/roseanne-...</td>\n",
       "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://local.theonion.com/mom-starting-to-fea...</td>\n",
       "      <td>mom starting to fear son's web series closest ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://politics.theonion.com/boehner-just-wan...</td>\n",
       "      <td>boehner just wants wife to listen, not come up...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/jk-rowlin...</td>\n",
       "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        article_link  ... is_sarcastic\n",
       "0  https://www.huffingtonpost.com/entry/versace-b...  ...            0\n",
       "1  https://www.huffingtonpost.com/entry/roseanne-...  ...            0\n",
       "2  https://local.theonion.com/mom-starting-to-fea...  ...            1\n",
       "3  https://politics.theonion.com/boehner-just-wan...  ...            1\n",
       "4  https://www.huffingtonpost.com/entry/jk-rowlin...  ...            0\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sarcasm_head.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "id": "pCIkgIP62EKx",
    "outputId": "6534d8f9-c36c-416c-c5e3-0641afc7d042"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>article_link</th>\n",
       "      <th>headline</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_sarcastic</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14985</td>\n",
       "      <td>14985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11724</td>\n",
       "      <td>11724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             article_link headline\n",
       "                    count    count\n",
       "is_sarcastic                      \n",
       "0                   14985    14985\n",
       "1                   11724    11724"
      ]
     },
     "execution_count": 64,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sarcasm_head.groupby(['is_sarcastic']).agg(['count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z6pXf7A78E2H"
   },
   "source": [
    "## Drop `article_link` from dataset. ( 2 marks)\n",
    "As we only need headline text data and is_sarcastic column for this project. We can drop artical link column here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "VLSVsvrlP9qD"
   },
   "outputs": [],
   "source": [
    "sarcasm_head = sarcasm_head.drop(['article_link'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 585
    },
    "id": "baVz8HQn3Jjm",
    "outputId": "446ef1ca-b646-4f0a-bc1f-b2e8b5d1edf0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>former versace store clerk sues over secret 'b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mom starting to fear son's web series closest ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>boehner just wants wife to listen, not come up...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  is_sarcastic\n",
       "0  former versace store clerk sues over secret 'b...             0\n",
       "1  the 'roseanne' revival catches up to our thorn...             0\n",
       "2  mom starting to fear son's web series closest ...             1\n",
       "3  boehner just wants wife to listen, not come up...             1\n",
       "4  j.k. rowling wishes snape happy birthday in th...             0"
      ]
     },
     "execution_count": 66,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sarcasm_head.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D0h6IOxU8OdH"
   },
   "source": [
    "## Get the Length of each line and find the maximum length. ( 4 marks)\n",
    "As different lines are of different length. We need to pad the our sequences using the max length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UQ-PjxQb6CfM",
    "outputId": "0ef120cd-6494-4682-c4a2-354d5f461b65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78\n"
     ]
    }
   ],
   "source": [
    "print(len(sarcasm_head[\"headline\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "Slb6X0cRALUI"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "BRAsChZAQmr3"
   },
   "outputs": [],
   "source": [
    "#print()\n",
    "en = np.zeros(sarcasm_head.headline.count())##, dtype=int)\n",
    "#en\n",
    "for i in range(0,sarcasm_head.headline.count()):\n",
    "  en[i] = len(sarcasm_head[\"headline\"][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_mTmHFM-B6FS",
    "outputId": "630d4577-23af-4e69-98ee-7420f08c7ae9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[78. 84. 79. ... 21. 60. 33.]\n"
     ]
    }
   ],
   "source": [
    "print(en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lqPsPZB0CvSY",
    "outputId": "a5329289-2a5c-467d-d68a-08c1ebdef7d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum length is  254.0 and the min length is 7.0\n"
     ]
    }
   ],
   "source": [
    "print(\"The maximum length is \", en.max(), \"and the min length is\", en.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VPPd0YuPXi2M"
   },
   "source": [
    "#**## Modelling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "35abKfRx8as3"
   },
   "source": [
    "## Import required modules required for modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "DVel73hYEV4r"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Flatten, Bidirectional, GlobalMaxPool1D\n",
    "from tensorflow.keras.models import Model, Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ziybaD1RdD9"
   },
   "source": [
    "# Set Different Parameters for the model. ( 2 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "jPw9gAN_EV6m"
   },
   "outputs": [],
   "source": [
    "max_features = 10000\n",
    "maxlen = int(en.max())\n",
    "embedding_size = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9abSe-bM8fn9"
   },
   "source": [
    "## Apply Keras Tokenizer of headline column of your data.  ( 4 marks)\n",
    "Hint - First create a tokenizer instance using Tokenizer(num_words=max_features) \n",
    "And then fit this tokenizer instance on your data column df['headline'] using .fit_on_texts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "T9Ad26HfTFMS"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(max_features)\n",
    "tokenizer.fit_on_texts(sarcasm_head['headline'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vF3mrXk9h9dT",
    "outputId": "3c6e6cfb-9f23-42d4-d7c9-169bf05beba0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "headline        object\n",
       "is_sarcastic     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 75,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sarcasm_head.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Ffi63KsST3P"
   },
   "source": [
    "# Define X and y for your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wnjxBdqmSS4s",
    "outputId": "05edaf4a-0543-496c-aa91-107e4da68c42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Samples: 26709\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0  307  678 3336 2297   47  381 2575    5\n",
      " 2576 8433]\n",
      "Number of Labels:  26709\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "X = tokenizer.texts_to_sequences(sarcasm_head['headline'])\n",
    "##print(X)\n",
    "##\"\"\"\n",
    "X = pad_sequences(X, maxlen = maxlen)\n",
    "y = np.asarray(sarcasm_head['is_sarcastic'])\n",
    "\n",
    "print(\"Number of Samples:\", len(X))\n",
    "print(X[0])\n",
    "print(\"Number of Labels: \", len(y))\n",
    "print(y[0])\n",
    "##\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WJLyKg-98rH_"
   },
   "source": [
    "## Get the Vocabulary size ( 2 marks)\n",
    "Hint : You can use tokenizer.word_index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q-2w0gHEUUIo",
    "outputId": "e4f6e18e-e4db-40d3-8ff3-473e3523f80e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Vocab size is  29656\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Vocab size is \", len(tokenizer.word_index))\n",
    "num_words = len(tokenizer.word_index)\n",
    "##tokenizer.word_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5hjeMi40XcB1"
   },
   "source": [
    "#**## Word Embedding**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bUF1TuQa8ux0"
   },
   "source": [
    "## Get Glove Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g3Bm53tpbiVk"
   },
   "source": [
    "### Do not run again - unziping files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "vq5AIfRtMeZh"
   },
   "outputs": [],
   "source": [
    "glove_file = project_path + \"glove.6B.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZmGlcc53QYpK",
    "outputId": "ce2deefc-2d17-43c1-c2e2-60315dd3f904"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/Sarcasm\n"
     ]
    }
   ],
   "source": [
    "cd /content/drive/MyDrive/Sarcasm/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "DJLX_n2WMecA"
   },
   "outputs": [],
   "source": [
    "#Extract Glove embedding zip file\n",
    "from zipfile import ZipFile\n",
    "with ZipFile(glove_file, 'r') as z:\n",
    "  z.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9IuXlu8-U3HG"
   },
   "source": [
    "# Get the Word Embeddings using Embedding file as given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "elZ-T5aFGZmZ"
   },
   "outputs": [],
   "source": [
    "EMBEDDING_FILE = './glove.6B.200d.txt' ### 200 dimensions is picked because embedding_size is 200. If embedding_size was 50 we would have chosed glove embedding with 50d i.e. the file name glove.6B.50d.txt\n",
    "\n",
    "embeddings = {}\n",
    "for o in open(EMBEDDING_FILE):\n",
    "    word = o.split(\" \")[0]\n",
    "    # print(word)\n",
    "    embd = o.split(\" \")[1:]\n",
    "    embd = np.asarray(embd, dtype='float32')\n",
    "    # print(embd)\n",
    "    embeddings[word] = embd\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bTPxveDmVCrA"
   },
   "source": [
    "# Create a weight matrix for words in training docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xQgOhiywU9nU",
    "outputId": "824dcde4-479c-4f4b-f0de-f72b0560916b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 79,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix = np.zeros((num_words+1, 200))\n",
    "\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "len(embeddings.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u7IbWuEX82Ra"
   },
   "source": [
    "## Create and Compile your Model  ( 7 marks)\n",
    "Hint - Use Sequential model instance and then add Embedding layer, Bidirectional(LSTM) layer, then dense and dropout layers as required. \n",
    "In the end add a final dense layer with sigmoid activation for binary classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "d7jhsSgYXG4l"
   },
   "outputs": [],
   "source": [
    "### Embedding layer for hint \n",
    "## model.add(Embedding(num_words, embedding_size, weights = [embedding_matrix]))\n",
    "### Bidirectional LSTM layer for hint \n",
    "## model.add(Bidirectional(LSTM(128, return_sequences = True)))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(num_words+1, embedding_size, weights = [embedding_matrix]))\n",
    "model.add(Bidirectional(LSTM(128, return_sequences = True)))\n",
    "#model.add(Dense(256))\n",
    "model.add(Dense(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(32))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(8))\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uZWamImAWzqC",
    "outputId": "b8625ad4-1110-4467-84a6-0d42214c1af8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_11 (Embedding)     (None, None, 200)         5931400   \n",
      "_________________________________________________________________\n",
      "bidirectional_11 (Bidirectio (None, None, 256)         336896    \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, None, 128)         32896     \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, None, 64)          8256      \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, None, 32)          2080      \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, None, 8)           264       \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, None, 1)           9         \n",
      "=================================================================\n",
      "Total params: 6,311,801\n",
      "Trainable params: 6,311,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "id": "6LkiV8rIW2TS"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IJFMxZwMWoTw"
   },
   "source": [
    "# Fit your model with a batch size of 100 and validation_split = 0.2. and state the validation accuracy ( 5 marks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZpVkajCcWnRK",
    "outputId": "1ea86450-b776-436e-eecd-434ac679a33a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "214/214 [==============================] - 28s 117ms/step - loss: 0.4354 - accuracy: 0.7958 - val_loss: 0.3545 - val_accuracy: 0.8519\n",
      "Epoch 2/5\n",
      "214/214 [==============================] - 24s 111ms/step - loss: 0.1786 - accuracy: 0.9338 - val_loss: 0.3890 - val_accuracy: 0.8526\n",
      "Epoch 3/5\n",
      "214/214 [==============================] - 24s 110ms/step - loss: 0.1179 - accuracy: 0.9574 - val_loss: 0.4123 - val_accuracy: 0.8457\n",
      "Epoch 4/5\n",
      "214/214 [==============================] - 24s 111ms/step - loss: 0.0808 - accuracy: 0.9730 - val_loss: 0.5571 - val_accuracy: 0.8440\n",
      "Epoch 5/5\n",
      "214/214 [==============================] - 24s 110ms/step - loss: 0.0582 - accuracy: 0.9806 - val_loss: 0.5870 - val_accuracy: 0.8435\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f542f807a90>"
      ]
     },
     "execution_count": 116,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 100\n",
    "epochs = 5\n",
    "model.fit(X, y, epochs=5, batch_size=100, validation_split=0.2)\n",
    "## Add your code here ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8U_VfzcUc0pp"
   },
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "_PgDsv0gcyEx"
   },
   "outputs": [],
   "source": [
    "y_predict = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sxdLfutkc_Jp",
    "outputId": "b95b6cf2-00e0-4d37-824a-4d357e621b83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explosion fells building outside paris, killing at least 2\n"
     ]
    }
   ],
   "source": [
    "print(sarcasm_head.headline[124])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rUDG0LP4kF__",
    "outputId": "443d7e54-2e1c-4be0-bf8b-505b0e8416ee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26709, 254)"
      ]
     },
     "execution_count": 103,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xlc7KEyfdf1o",
    "outputId": "ac36a753-59e5-4e4c-e80a-b2acbbd09fad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26709,)"
      ]
     },
     "execution_count": 104,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kPOpvc3oc7Nh",
    "outputId": "01f8f8eb-5f23-4f8e-c1d4-117d711af933"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.1615266 ]\n",
      " [0.16547391]\n",
      " [0.1682866 ]\n",
      " [0.17003538]\n",
      " [0.17086448]\n",
      " [0.17098483]\n",
      " [0.1706465 ]\n",
      " [0.17009865]\n",
      " [0.16955072]\n",
      " [0.16914815]\n",
      " [0.16896477]\n",
      " [0.16901089]\n",
      " [0.16924879]\n",
      " [0.16961092]\n",
      " [0.17001893]\n",
      " [0.17039827]\n",
      " [0.17069082]\n",
      " [0.17086214]\n",
      " [0.17090416]\n",
      " [0.1708327 ]\n",
      " [0.17068118]\n",
      " [0.17049095]\n",
      " [0.17030303]\n",
      " [0.17015013]\n",
      " [0.17005283]\n",
      " [0.17001799]\n",
      " [0.17004001]\n",
      " [0.17010489]\n",
      " [0.17019324]\n",
      " [0.17028552]\n",
      " [0.17036502]\n",
      " [0.17041981]\n",
      " [0.17044497]\n",
      " [0.17044118]\n",
      " [0.17041446]\n",
      " [0.17037366]\n",
      " [0.17032847]\n",
      " [0.17028761]\n",
      " [0.17025745]\n",
      " [0.17024139]\n",
      " [0.17023967]\n",
      " [0.17025   ]\n",
      " [0.17026834]\n",
      " [0.17029007]\n",
      " [0.17031074]\n",
      " [0.17032695]\n",
      " [0.17033659]\n",
      " [0.17033921]\n",
      " [0.17033565]\n",
      " [0.17032759]\n",
      " [0.17031726]\n",
      " [0.17030698]\n",
      " [0.1702984 ]\n",
      " [0.17029282]\n",
      " [0.17029066]\n",
      " [0.17029169]\n",
      " [0.17029513]\n",
      " [0.17029989]\n",
      " [0.17030501]\n",
      " [0.17030944]\n",
      " [0.17031248]\n",
      " [0.17031401]\n",
      " [0.17031391]\n",
      " [0.17031254]\n",
      " [0.17031038]\n",
      " [0.17030784]\n",
      " [0.17030564]\n",
      " [0.1703039 ]\n",
      " [0.17030296]\n",
      " [0.17030287]\n",
      " [0.17030334]\n",
      " [0.17030431]\n",
      " [0.17030555]\n",
      " [0.17030667]\n",
      " [0.17030753]\n",
      " [0.17030811]\n",
      " [0.17030823]\n",
      " [0.17030814]\n",
      " [0.17030773]\n",
      " [0.17030716]\n",
      " [0.17030655]\n",
      " [0.1703061 ]\n",
      " [0.17030577]\n",
      " [0.17030567]\n",
      " [0.17030571]\n",
      " [0.17030588]\n",
      " [0.17030613]\n",
      " [0.17030643]\n",
      " [0.17030665]\n",
      " [0.1703068 ]\n",
      " [0.1703069 ]\n",
      " [0.17030694]\n",
      " [0.17030686]\n",
      " [0.17030671]\n",
      " [0.17030658]\n",
      " [0.17030644]\n",
      " [0.17030634]\n",
      " [0.17030628]\n",
      " [0.1703063 ]\n",
      " [0.17030632]\n",
      " [0.17030635]\n",
      " [0.17030641]\n",
      " [0.1703065 ]\n",
      " [0.17030658]\n",
      " [0.17030652]\n",
      " [0.17030656]\n",
      " [0.17030658]\n",
      " [0.17030655]\n",
      " [0.17030652]\n",
      " [0.1703065 ]\n",
      " [0.1703065 ]\n",
      " [0.17030649]\n",
      " [0.17030649]\n",
      " [0.17030647]\n",
      " [0.17030643]\n",
      " [0.1703065 ]\n",
      " [0.17030652]\n",
      " [0.17030649]\n",
      " [0.17030652]\n",
      " [0.17030655]\n",
      " [0.17030652]\n",
      " [0.17030649]\n",
      " [0.17030647]\n",
      " [0.17030652]\n",
      " [0.17030649]\n",
      " [0.17030649]\n",
      " [0.1703065 ]\n",
      " [0.17030649]\n",
      " [0.1703065 ]\n",
      " [0.17030649]\n",
      " [0.1703065 ]\n",
      " [0.17030649]\n",
      " [0.17030649]\n",
      " [0.17030652]\n",
      " [0.17030652]\n",
      " [0.1703065 ]\n",
      " [0.17030649]\n",
      " [0.1703065 ]\n",
      " [0.1703065 ]\n",
      " [0.1703065 ]\n",
      " [0.1703065 ]\n",
      " [0.17030649]\n",
      " [0.1703065 ]\n",
      " [0.17030641]\n",
      " [0.17030644]\n",
      " [0.17030647]\n",
      " [0.17030649]\n",
      " [0.17030647]\n",
      " [0.17030647]\n",
      " [0.17030649]\n",
      " [0.17030647]\n",
      " [0.17030644]\n",
      " [0.17030649]\n",
      " [0.17030647]\n",
      " [0.17030647]\n",
      " [0.17030647]\n",
      " [0.17030649]\n",
      " [0.17030644]\n",
      " [0.17030644]\n",
      " [0.17030643]\n",
      " [0.17030644]\n",
      " [0.17030652]\n",
      " [0.1703065 ]\n",
      " [0.17030647]\n",
      " [0.17030649]\n",
      " [0.17030647]\n",
      " [0.17030649]\n",
      " [0.17030647]\n",
      " [0.17030649]\n",
      " [0.17030655]\n",
      " [0.17030649]\n",
      " [0.17030652]\n",
      " [0.17030652]\n",
      " [0.17030649]\n",
      " [0.17030649]\n",
      " [0.17030644]\n",
      " [0.17030647]\n",
      " [0.17030643]\n",
      " [0.1703064 ]\n",
      " [0.17030635]\n",
      " [0.1703064 ]\n",
      " [0.17030632]\n",
      " [0.17030632]\n",
      " [0.17030632]\n",
      " [0.17030627]\n",
      " [0.17030622]\n",
      " [0.17030613]\n",
      " [0.17030613]\n",
      " [0.17030601]\n",
      " [0.17030594]\n",
      " [0.17030588]\n",
      " [0.17030567]\n",
      " [0.17030556]\n",
      " [0.17030536]\n",
      " [0.17030518]\n",
      " [0.17030491]\n",
      " [0.17030461]\n",
      " [0.17030431]\n",
      " [0.17030385]\n",
      " [0.17030343]\n",
      " [0.17030287]\n",
      " [0.17030224]\n",
      " [0.1703014 ]\n",
      " [0.17030054]\n",
      " [0.17029954]\n",
      " [0.1702983 ]\n",
      " [0.17029682]\n",
      " [0.17029521]\n",
      " [0.17029327]\n",
      " [0.17029107]\n",
      " [0.17028855]\n",
      " [0.17028552]\n",
      " [0.17028213]\n",
      " [0.1702782 ]\n",
      " [0.17027377]\n",
      " [0.1702687 ]\n",
      " [0.17026292]\n",
      " [0.17025656]\n",
      " [0.17024943]\n",
      " [0.1702416 ]\n",
      " [0.17023319]\n",
      " [0.17022428]\n",
      " [0.17021514]\n",
      " [0.17020611]\n",
      " [0.17019807]\n",
      " [0.17019205]\n",
      " [0.17018981]\n",
      " [0.1701943 ]\n",
      " [0.17020977]\n",
      " [0.17024359]\n",
      " [0.17030773]\n",
      " [0.17042212]\n",
      " [0.17062092]\n",
      " [0.17096473]\n",
      " [0.17156412]\n",
      " [0.17262845]\n",
      " [0.17456867]\n",
      " [0.17821527]\n",
      " [0.1852389 ]\n",
      " [0.1987212 ]\n",
      " [0.22293964]\n",
      " [0.26023573]\n",
      " [0.3065183 ]\n",
      " [0.35323665]\n",
      " [0.39440063]\n",
      " [0.42909026]\n",
      " [0.38766518]\n",
      " [0.38852733]\n",
      " [0.37827542]\n",
      " [0.146987  ]\n",
      " [0.10202403]\n",
      " [0.0983652 ]\n",
      " [0.09094981]\n",
      " [0.06216545]]\n"
     ]
    }
   ],
   "source": [
    "y_predict.shape\n",
    "print(y_predict[124])\n",
    "#print(\"Predicted is \", y_predict[123],\"and Actual is\", y[123])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2dr00DqCm9nL",
    "outputId": "94fb5f9c-53b9-4b1b-fef9-98da17520d59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dad recommends hotel 10 miles away from city you're visiting\n"
     ]
    }
   ],
   "source": [
    "print(sarcasm_head.headline[123])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DUSkFfSenBnw",
    "outputId": "474f98bf-5a5f-418b-a138-dae7b1ce09e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted is  [[0.8499248 ]\n",
      " [0.8535693 ]\n",
      " [0.8560799 ]\n",
      " [0.8576062 ]\n",
      " [0.85832083]\n",
      " [0.858424  ]\n",
      " [0.85813344]\n",
      " [0.8576609 ]\n",
      " [0.8571859 ]\n",
      " [0.85683507]\n",
      " [0.8566749 ]\n",
      " [0.85671526]\n",
      " [0.85692286]\n",
      " [0.8572381 ]\n",
      " [0.857592  ]\n",
      " [0.85791963]\n",
      " [0.8581715 ]\n",
      " [0.8583187 ]\n",
      " [0.8583548 ]\n",
      " [0.8582934 ]\n",
      " [0.8581633 ]\n",
      " [0.8579996 ]\n",
      " [0.85783744]\n",
      " [0.85770535]\n",
      " [0.8576214 ]\n",
      " [0.8575911 ]\n",
      " [0.8576102 ]\n",
      " [0.85766625]\n",
      " [0.8577427 ]\n",
      " [0.8578225 ]\n",
      " [0.85789096]\n",
      " [0.85793823]\n",
      " [0.85795987]\n",
      " [0.8579567 ]\n",
      " [0.8579336 ]\n",
      " [0.8578984 ]\n",
      " [0.8578594 ]\n",
      " [0.85782415]\n",
      " [0.85779816]\n",
      " [0.8577843 ]\n",
      " [0.8577828 ]\n",
      " [0.85779166]\n",
      " [0.8578075 ]\n",
      " [0.8578263 ]\n",
      " [0.85784423]\n",
      " [0.85785806]\n",
      " [0.85786647]\n",
      " [0.8578688 ]\n",
      " [0.85786563]\n",
      " [0.85785866]\n",
      " [0.85784984]\n",
      " [0.8578409 ]\n",
      " [0.8578335 ]\n",
      " [0.8578287 ]\n",
      " [0.8578268 ]\n",
      " [0.8578277 ]\n",
      " [0.8578307 ]\n",
      " [0.85783476]\n",
      " [0.8578391 ]\n",
      " [0.857843  ]\n",
      " [0.8578457 ]\n",
      " [0.85784703]\n",
      " [0.8578469 ]\n",
      " [0.8578457 ]\n",
      " [0.8578439 ]\n",
      " [0.8578417 ]\n",
      " [0.8578398 ]\n",
      " [0.8578382 ]\n",
      " [0.8578374 ]\n",
      " [0.85783726]\n",
      " [0.8578378 ]\n",
      " [0.8578386 ]\n",
      " [0.85783964]\n",
      " [0.8578407 ]\n",
      " [0.8578414 ]\n",
      " [0.8578419 ]\n",
      " [0.857842  ]\n",
      " [0.8578419 ]\n",
      " [0.8578415 ]\n",
      " [0.8578411 ]\n",
      " [0.8578406 ]\n",
      " [0.8578402 ]\n",
      " [0.8578398 ]\n",
      " [0.85783964]\n",
      " [0.8578397 ]\n",
      " [0.8578399 ]\n",
      " [0.8578402 ]\n",
      " [0.8578404 ]\n",
      " [0.8578406 ]\n",
      " [0.8578408 ]\n",
      " [0.8578409 ]\n",
      " [0.8578409 ]\n",
      " [0.8578408 ]\n",
      " [0.8578407 ]\n",
      " [0.8578406 ]\n",
      " [0.8578404 ]\n",
      " [0.8578404 ]\n",
      " [0.85784036]\n",
      " [0.85784036]\n",
      " [0.85784036]\n",
      " [0.8578404 ]\n",
      " [0.8578404 ]\n",
      " [0.85784054]\n",
      " [0.8578406 ]\n",
      " [0.8578406 ]\n",
      " [0.8578406 ]\n",
      " [0.8578406 ]\n",
      " [0.8578406 ]\n",
      " [0.85784054]\n",
      " [0.85784054]\n",
      " [0.8578404 ]\n",
      " [0.8578404 ]\n",
      " [0.8578404 ]\n",
      " [0.85784054]\n",
      " [0.85784054]\n",
      " [0.85784054]\n",
      " [0.85784054]\n",
      " [0.85784054]\n",
      " [0.85784054]\n",
      " [0.85784054]\n",
      " [0.85784054]\n",
      " [0.85784054]\n",
      " [0.85784054]\n",
      " [0.85784054]\n",
      " [0.85784054]\n",
      " [0.85784054]\n",
      " [0.85784054]\n",
      " [0.85784054]\n",
      " [0.85784054]\n",
      " [0.85784054]\n",
      " [0.85784054]\n",
      " [0.85784054]\n",
      " [0.85784054]\n",
      " [0.85784054]\n",
      " [0.85784054]\n",
      " [0.85784054]\n",
      " [0.85784054]\n",
      " [0.85784054]\n",
      " [0.85784054]\n",
      " [0.85784054]\n",
      " [0.85784054]\n",
      " [0.85784054]\n",
      " [0.85784054]\n",
      " [0.85784054]\n",
      " [0.85784054]\n",
      " [0.85784054]\n",
      " [0.85784054]\n",
      " [0.85784054]\n",
      " [0.8578404 ]\n",
      " [0.85784054]\n",
      " [0.85784054]\n",
      " [0.85784054]\n",
      " [0.85784054]\n",
      " [0.85784054]\n",
      " [0.85784054]\n",
      " [0.85784054]\n",
      " [0.85784054]\n",
      " [0.85784054]\n",
      " [0.85784054]\n",
      " [0.85784054]\n",
      " [0.8578404 ]\n",
      " [0.8578404 ]\n",
      " [0.85784036]\n",
      " [0.8578404 ]\n",
      " [0.8578404 ]\n",
      " [0.8578404 ]\n",
      " [0.8578404 ]\n",
      " [0.85784036]\n",
      " [0.85784036]\n",
      " [0.85784036]\n",
      " [0.85784036]\n",
      " [0.85784036]\n",
      " [0.85784036]\n",
      " [0.85784024]\n",
      " [0.8578402 ]\n",
      " [0.8578402 ]\n",
      " [0.8578402 ]\n",
      " [0.8578402 ]\n",
      " [0.85784006]\n",
      " [0.85784   ]\n",
      " [0.85784   ]\n",
      " [0.8578399 ]\n",
      " [0.8578398 ]\n",
      " [0.8578397 ]\n",
      " [0.85783964]\n",
      " [0.8578396 ]\n",
      " [0.8578394 ]\n",
      " [0.8578393 ]\n",
      " [0.8578391 ]\n",
      " [0.8578389 ]\n",
      " [0.85783875]\n",
      " [0.8578387 ]\n",
      " [0.8578384 ]\n",
      " [0.85783815]\n",
      " [0.8578379 ]\n",
      " [0.8578376 ]\n",
      " [0.8578374 ]\n",
      " [0.857837  ]\n",
      " [0.8578367 ]\n",
      " [0.8578364 ]\n",
      " [0.8578361 ]\n",
      " [0.85783577]\n",
      " [0.85783553]\n",
      " [0.85783523]\n",
      " [0.85783505]\n",
      " [0.857835  ]\n",
      " [0.85783505]\n",
      " [0.85783535]\n",
      " [0.85783577]\n",
      " [0.8578365 ]\n",
      " [0.85783756]\n",
      " [0.85783905]\n",
      " [0.85784113]\n",
      " [0.85784376]\n",
      " [0.8578472 ]\n",
      " [0.8578515 ]\n",
      " [0.8578569 ]\n",
      " [0.8578634 ]\n",
      " [0.8578714 ]\n",
      " [0.8578807 ]\n",
      " [0.85789156]\n",
      " [0.8579042 ]\n",
      " [0.85791826]\n",
      " [0.8579339 ]\n",
      " [0.8579506 ]\n",
      " [0.8579681 ]\n",
      " [0.8579854 ]\n",
      " [0.8580016 ]\n",
      " [0.8580151 ]\n",
      " [0.8580242 ]\n",
      " [0.85802656]\n",
      " [0.85801953]\n",
      " [0.85799986]\n",
      " [0.8579629 ]\n",
      " [0.8579023 ]\n",
      " [0.8578056 ]\n",
      " [0.8576494 ]\n",
      " [0.8573854 ]\n",
      " [0.8569158 ]\n",
      " [0.8560477 ]\n",
      " [0.85440916]\n",
      " [0.85130847]\n",
      " [0.84562707]\n",
      " [0.83426416]\n",
      " [0.84287864]\n",
      " [0.9158721 ]\n",
      " [0.9422766 ]\n",
      " [0.9422452 ]\n",
      " [0.95205045]\n",
      " [0.9564631 ]\n",
      " [0.9521043 ]\n",
      " [0.95649976]\n",
      " [0.93194735]\n",
      " [0.95603305]] and Actual is 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicted is \", y_predict[123],\"and Actual is\", y[123])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qsrMCFOKnGyZ"
   },
   "source": [
    "### I wonder why y predict is a 254x1 for a single headline. Shouldn't it be just 1?"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "NLP_Project_Sarcasm_Detection_Questions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
